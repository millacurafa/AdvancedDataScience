{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ejemplo PyCUDA.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/millacurafa/AdvancedDataScience/blob/main/Ejemplo_PyCUDA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Tzk-sAMFRIp",
        "outputId": "572c62a2-25aa-4b28-eb97-5cef582c982f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "!pip install pycuda"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pycuda\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/46/61/47d3235a4c13eec5a5f03594ddb268f4858734e02980afbcd806e6242fa5/pycuda-2020.1.tar.gz (1.6MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6MB 11.1MB/s \n",
            "\u001b[?25hCollecting pytools>=2011.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b7/30/c9362a282ef89106768cba9d884f4b2e4f5dc6881d0c19b478d2a710b82b/pytools-2020.4.3.tar.gz (62kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 10.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: decorator>=3.2.0 in /usr/local/lib/python3.6/dist-packages (from pycuda) (4.4.2)\n",
            "Collecting appdirs>=1.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/3b/00/2344469e2084fb287c2e0b57b72910309874c3245463acd6cf5e3db69324/appdirs-1.4.4-py2.py3-none-any.whl\n",
            "Collecting mako\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/37/0e706200d22172eb8fa17d68a7ae22dec7631a0a92266634fb518a88a5b2/Mako-1.1.3-py2.py3-none-any.whl (75kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 12.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.8.0 in /usr/local/lib/python3.6/dist-packages (from pytools>=2011.2->pycuda) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from pytools>=2011.2->pycuda) (1.18.5)\n",
            "Requirement already satisfied: dataclasses>=0.7 in /usr/local/lib/python3.6/dist-packages (from pytools>=2011.2->pycuda) (0.7)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from mako->pycuda) (1.1.1)\n",
            "Building wheels for collected packages: pycuda, pytools\n",
            "  Building wheel for pycuda (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycuda: filename=pycuda-2020.1-cp36-cp36m-linux_x86_64.whl size=620777 sha256=3098af469269f226a84ad28a9d29a572550ff044161136ecaf2f698d578e4e93\n",
            "  Stored in directory: /root/.cache/pip/wheels/8f/78/d1/5bb826f81d9d490297a348d818ff3ee6dd6f2075b06dde6ea0\n",
            "  Building wheel for pytools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytools: filename=pytools-2020.4.3-py2.py3-none-any.whl size=61374 sha256=fc569958be3b3241ad1cdaa2236239658e196819e329dc8bf7060a8fa00d52c8\n",
            "  Stored in directory: /root/.cache/pip/wheels/af/c7/81/a22edb90b0b09a880468b2253bb1df8e9f503337ee15432c64\n",
            "Successfully built pycuda pytools\n",
            "Installing collected packages: appdirs, pytools, mako, pycuda\n",
            "Successfully installed appdirs-1.4.4 mako-1.1.3 pycuda-2020.1 pytools-2020.4.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aP-hxyCoHuix",
        "outputId": "70a53704-2511-4eaa-ab59-291cc5b4fb07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "from pycuda.compiler import SourceModule\n",
        "\n",
        "import numpy\n",
        "\n",
        "#Se crea matriz de 4x4 con números del 0 al 9\n",
        "a = numpy.random.randint(10, size=(8,8))\n",
        "#Se convierte el tipo de dato de int64 a int32\n",
        "a = a.astype(numpy.int32)\n",
        "\n",
        "#Se asigna la la memoria en la GPU con la cantidad de bytes que ocupa la matriz a \n",
        "a_gpu = cuda.mem_alloc(a.nbytes)\n",
        "#Se realiza la copia de los datos de host -> device\n",
        "cuda.memcpy_htod(a_gpu, a)\n",
        "\n",
        "#Kernel CUDA, es la función que va a ejecutar cada hebra instanciada\n",
        "# Documento para índices de hebras https://cs.calvin.edu/courses/cs/374/CUDA/CUDA-Thread-Indexing-Cheatsheet.pdf\n",
        "\n",
        "# Para una GTX 1080\n",
        "# Maximum number of threads per block:           1024\n",
        "# Max dimension size of a thread block (x,y,z): (1024, 1024, 64)\n",
        "# Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)\n",
        "\n",
        "\n",
        "mod = SourceModule(\"\"\"\n",
        "   __global__ void doublify(int *a)\n",
        "   {\n",
        "  \n",
        "     int blockId = blockIdx.x + blockIdx.y * gridDim.x;\n",
        "     int idx = blockId * (blockDim.x * blockDim.y) + (threadIdx.y * blockDim.x) + threadIdx.x;\n",
        "\n",
        "     a[idx] *= 2;\n",
        "   }\n",
        "   \"\"\")\n",
        "\n",
        "#Convierte el kernel a una función en python\n",
        "func = mod.get_function(\"doublify\")\n",
        "#Se ejecuta el kernel, con bloques de tamaño 4x4x1\n",
        "\n",
        "start = cuda.Event()\n",
        "end   = cuda.Event()\n",
        "\n",
        "start.record()\n",
        "func(a_gpu, block=(16,16,1),grid=(2,2,1))\n",
        "end.record()\n",
        "end.synchronize()\n",
        "\n",
        "millis = start.time_till(end)\n",
        "print(\"Tiempo: \" + str(millis))\n",
        "#Devuelve un nuevo arreglo con la misma forma y tipo del arreglo dado\n",
        "a_doubled = numpy.empty_like(a)\n",
        "\n",
        "#Se realiza la copia de los datos de device -> host\n",
        "cuda.memcpy_dtoh(a_doubled, a_gpu)\n",
        "\n",
        "print(a)\n",
        "print()\n",
        "print(a_doubled)\n",
        "print()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tiempo: 0.088128000497818\n",
            "[[9 9 5 6 5 0 6 7]\n",
            " [1 1 4 4 0 3 6 3]\n",
            " [0 9 1 5 1 6 6 8]\n",
            " [6 4 1 4 7 3 7 5]\n",
            " [8 2 0 7 3 6 9 7]\n",
            " [8 9 5 5 3 8 9 6]\n",
            " [3 2 3 7 2 9 1 9]\n",
            " [4 2 6 8 7 0 7 8]]\n",
            "\n",
            "[[18 18 10 12 10  0 12 14]\n",
            " [ 2  2  8  8  0  6 12  6]\n",
            " [ 0 18  2 10  2 12 12 16]\n",
            " [12  8  2  8 14  6 14 10]\n",
            " [16  4  0 14  6 12 18 14]\n",
            " [16 18 10 10  6 16 18 12]\n",
            " [ 6  4  6 14  4 18  2 18]\n",
            " [ 8  4 12 16 14  0 14 16]]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}